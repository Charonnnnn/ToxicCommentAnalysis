{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/charon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/charon/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/charon/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://blog.csdn.net/zhuzuwei/article/details/79006798\n",
    "# http://blog.sina.com.cn/s/blog_6d65717d0100z4hu.html   !!!!\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# print(string.punctuation)\n",
    "def mytoken_lemm(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    lemms = []\n",
    "    for item in words:\n",
    "        lemms.append(WordNetLemmatizer().lemmatize(item))\n",
    "    return lemms\n",
    "\n",
    "def mytoken_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    stems = []\n",
    "    for item in words:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems\n",
    "\n",
    "def mytoken2(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    return words\n",
    "\n",
    "def mytoken3(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stems = []\n",
    "    for item in tokens:\n",
    "        stems.append(PorterStemmer().stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fact', 'dataset', 'need', 'predict', 'four', 'valu', 'use', 'fool', 'way', 'predict']\n",
      "['fact', 'dataset', 'need', 'predict', 'four', 'value', 'using', 'fool', 'way', 'prediction']\n",
      "['In', 'fact', ',', 'dataset', 'need', 'to', 'predict', 'the', 'four', 'valu', '.', 'I', 'am', 'use', 'some', 'fool', 'way', 'to', 'do', 'the', 'predict']\n"
     ]
    }
   ],
   "source": [
    "tets = 'In fact, dataset need to predict the four value. I am using some fool way to do the prediction'\n",
    "text = '''Sentiment analysis is a challenging subject in machine learning.\\\n",
    " People express their emotions in language that is often obscured by sarcasm,\\\n",
    "  ambiguity, and plays on words, all of which could be very misleading for \\\n",
    "  both humans and computers. There's another Kaggle competition for movie review \\\n",
    "  sentiment analysis. In this tutorial we explore how Word2Vec can be applied to \\\n",
    "  a similar problem.--------------------- 作者：zhuzuwei 来源：CSDN 原文：https://blog.csdn.net/zhuzuwei/article/details/79006798 版权声明：本文为博主原创文章，转载请附上博文链接！In fact, dataset need to predict the four value. I am using some'''\n",
    "print(mytoken_stem(tets))\n",
    "print(mytoken2(tets))\n",
    "print(mytoken3(tets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment',\n",
       " 'analysi',\n",
       " 'challeng',\n",
       " 'subject',\n",
       " 'machin',\n",
       " 'learn',\n",
       " 'peopl',\n",
       " 'express',\n",
       " 'emot',\n",
       " 'languag',\n",
       " 'often',\n",
       " 'obscur',\n",
       " 'sarcasm',\n",
       " 'ambigu',\n",
       " 'play',\n",
       " 'word',\n",
       " 'could',\n",
       " 'mislead',\n",
       " 'human',\n",
       " 'comput',\n",
       " 'anoth',\n",
       " 'kaggl',\n",
       " 'competit',\n",
       " 'movi',\n",
       " 'review',\n",
       " 'sentiment',\n",
       " 'analysi',\n",
       " 'tutori',\n",
       " 'explor',\n",
       " 'appli',\n",
       " 'similar',\n",
       " 'problem',\n",
       " 'fact',\n",
       " 'dataset',\n",
       " 'need',\n",
       " 'predict',\n",
       " 'four',\n",
       " 'valu',\n",
       " 'use']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytoken_stem(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fact',\n",
       " 'dataset',\n",
       " 'need',\n",
       " 'predict',\n",
       " 'four',\n",
       " 'value',\n",
       " 'using',\n",
       " 'fool',\n",
       " 'way',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytoken_lemm(tets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment',\n",
       " 'analysis',\n",
       " 'challenging',\n",
       " 'subject',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'people',\n",
       " 'express',\n",
       " 'emotion',\n",
       " 'language',\n",
       " 'often',\n",
       " 'obscured',\n",
       " 'sarcasm',\n",
       " 'ambiguity',\n",
       " 'play',\n",
       " 'word',\n",
       " 'could',\n",
       " 'misleading',\n",
       " 'human',\n",
       " 'computer',\n",
       " 'another',\n",
       " 'kaggle',\n",
       " 'competition',\n",
       " 'movie',\n",
       " 'review',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " 'tutorial',\n",
       " 'explore',\n",
       " 'applied',\n",
       " 'similar',\n",
       " 'problem',\n",
       " 'fact',\n",
       " 'dataset',\n",
       " 'need',\n",
       " 'predict',\n",
       " 'four',\n",
       " 'value',\n",
       " 'using']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytoken_lemm(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
